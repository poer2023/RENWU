#!/usr/bin/env python3
"""
Enhanced Risk Radar Testing Suite
æµ‹è¯•å¢å¼ºç‰ˆé£é™©é›·è¾¾åŠŸèƒ½çš„å…¨é¢æµ‹è¯•å¥—ä»¶
"""

import unittest
import json
import sys
import os
from datetime import datetime, timedelta

# Add backend directory to path
sys.path.append(os.path.join(os.path.dirname(__file__)))
from app.utils.ai_client import AIClient

class TestEnhancedRiskRadar(unittest.TestCase):
    """å¢å¼ºç‰ˆé£é™©é›·è¾¾æµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.ai_client = AIClient()
        
        # åˆ›å»ºæµ‹è¯•ä»»åŠ¡æ•°æ®
        self.test_tasks = [
            {
                "id": 1,
                "title": "ç´§æ€¥ä¿®å¤ç™»å½•bug",
                "description": "ç”¨æˆ·åé¦ˆç™»å½•åŠŸèƒ½é˜»å¡ï¼Œéœ€è¦ç´§æ€¥å¤„ç†ï¼Œå‹åŠ›å¾ˆå¤§",
                "urgency": 0,  # P0 Critical
                "module_id": 1,
                "created_at": (datetime.now() - timedelta(days=45)).isoformat(),
                "due_date": (datetime.now() - timedelta(days=2)).isoformat(),  # Overdue
                "dependencies": [2, 3]
            },
            {
                "id": 2,
                "title": "ç­‰å¾…ç¬¬ä¸‰æ–¹APIæ–‡æ¡£",
                "description": "å¤–éƒ¨ä¾›åº”å•†è¿˜æœªæä¾›APIæ–‡æ¡£ï¼Œé¡¹ç›®è¢«é˜»å¡",
                "urgency": 1,  # P1 High
                "module_id": 1,
                "created_at": (datetime.now() - timedelta(days=20)).isoformat(),
                "dependencies": []
            },
            {
                "id": 3,
                "title": "å¤æ‚çš„æ•°æ®åº“é‡æ„",
                "description": "éœ€è¦é‡æ„è€ä»£ç ï¼ŒæŠ€æœ¯å€ºåŠ¡è¾ƒå¤šï¼Œä¸ç¡®å®šå…·ä½“å·¥ä½œé‡",
                "urgency": 2,  # P2 Medium
                "module_id": 2,
                "created_at": (datetime.now() - timedelta(days=35)).isoformat(),
                "dependencies": [4, 5, 6, 7]  # High dependency
            },
            {
                "id": 4,
                "title": "ç®€å•çš„UIè°ƒæ•´",
                "description": "è°ƒæ•´æŒ‰é’®é¢œè‰²",
                "urgency": 3,  # P3 Low
                "module_id": 1,
                "created_at": (datetime.now() - timedelta(days=5)).isoformat(),
                "dependencies": []
            },
            {
                "id": 5,
                "title": "å›¢é˜Ÿæ²Ÿé€šé—®é¢˜",
                "description": "éœ€æ±‚ç†è§£åå·®ï¼Œæ²Ÿé€šä¸ç•…ï¼Œé€ æˆè¯¯è§£",
                "urgency": 1,
                "module_id": 2,
                "created_at": (datetime.now() - timedelta(days=15)).isoformat(),
                "dependencies": []
            },
            {
                "id": 6,
                "title": "èµ„æºå†²çªä»»åŠ¡1",
                "description": "äººæ‰‹ä¸å¤Ÿï¼Œèµ„æºä¸è¶³",
                "urgency": 2,
                "module_id": 1,  # Same module as many others
                "created_at": (datetime.now() - timedelta(days=10)).isoformat(),
                "dependencies": []
            },
            {
                "id": 7,
                "title": "èµ„æºå†²çªä»»åŠ¡2", 
                "description": "ç«äº‰åŒä¸€èµ„æº",
                "urgency": 2,
                "module_id": 1,  # Same module
                "created_at": (datetime.now() - timedelta(days=8)).isoformat(),
                "dependencies": []
            },
            {
                "id": 8,
                "title": "å³å°†åˆ°æœŸä»»åŠ¡",
                "description": "æ˜å¤©å°±è¦äº¤ä»˜äº†",
                "urgency": 1,
                "module_id": 3,
                "created_at": (datetime.now() - timedelta(days=3)).isoformat(),
                "due_date": (datetime.now() + timedelta(days=1)).isoformat(),  # Due soon
                "dependencies": []
            }
        ]
    
    def test_enhanced_risk_analysis_basic(self):
        """æµ‹è¯•åŸºç¡€é£é™©åˆ†æåŠŸèƒ½"""
        print("\nğŸ§ª æµ‹è¯•åŸºç¡€é£é™©åˆ†æåŠŸèƒ½...")
        
        result = self.ai_client.analyze_task_risks(self.test_tasks)
        
        # éªŒè¯è¿”å›ç»“æ„
        self.assertIn("risk_summary", result)
        self.assertIn("risky_tasks", result)
        self.assertIn("suggestions", result)
        self.assertIn("risk_distribution", result)
        self.assertIn("action_items", result)
        self.assertIn("project_insights", result)
        
        print("âœ… åŸºç¡€ç»“æ„éªŒè¯é€šè¿‡")
        
        # éªŒè¯é£é™©æ‘˜è¦
        risk_summary = result["risk_summary"]
        self.assertIn("project_health_score", risk_summary)
        self.assertIn("risk_trends", risk_summary)
        self.assertEqual(risk_summary["total_tasks"], len(self.test_tasks))
        
        print(f"ğŸ“Š é¡¹ç›®å¥åº·åº¦: {risk_summary['project_health_score']}")
        print(f"ğŸ“ˆ é«˜é£é™©ä»»åŠ¡: {risk_summary['high_risk']}")
        print(f"ğŸ“Š ä¸­é£é™©ä»»åŠ¡: {risk_summary['medium_risk']}")
        print(f"ğŸ“‰ ä½é£é™©ä»»åŠ¡: {risk_summary['low_risk']}")
    
    def test_enhanced_risk_categories(self):
        """æµ‹è¯•å¢å¼ºçš„é£é™©åˆ†ç±»"""
        print("\nğŸ§ª æµ‹è¯•å¢å¼ºçš„é£é™©åˆ†ç±»...")
        
        result = self.ai_client.analyze_task_risks(self.test_tasks)
        risk_categories = result["risk_summary"]["risk_categories"]
        
        # éªŒè¯æ–°å¢çš„é£é™©åˆ†ç±»
        expected_categories = [
            "delay", "blocked", "external_dependency", "complexity",
            "emotional_stress", "resource_conflict", "technical_debt", "communication"
        ]
        
        for category in expected_categories:
            self.assertIn(category, risk_categories)
            
        print("âœ… æ‰€æœ‰é£é™©åˆ†ç±»éƒ½å­˜åœ¨")
        
        # éªŒè¯ç‰¹å®šé£é™©è¢«æ­£ç¡®è¯†åˆ«
        self.assertGreater(risk_categories["blocked"], 0, "åº”è¯¥æ£€æµ‹åˆ°é˜»å¡é£é™©")
        self.assertGreater(risk_categories["external_dependency"], 0, "åº”è¯¥æ£€æµ‹åˆ°å¤–éƒ¨ä¾èµ–é£é™©")
        self.assertGreater(risk_categories["complexity"], 0, "åº”è¯¥æ£€æµ‹åˆ°å¤æ‚åº¦é£é™©")
        self.assertGreater(risk_categories["emotional_stress"], 0, "åº”è¯¥æ£€æµ‹åˆ°å‹åŠ›é£é™©")
        self.assertGreater(risk_categories["resource_conflict"], 0, "åº”è¯¥æ£€æµ‹åˆ°èµ„æºå†²çªé£é™©")
        self.assertGreater(risk_categories["technical_debt"], 0, "åº”è¯¥æ£€æµ‹åˆ°æŠ€æœ¯å€ºåŠ¡é£é™©")
        self.assertGreater(risk_categories["communication"], 0, "åº”è¯¥æ£€æµ‹åˆ°æ²Ÿé€šé£é™©")
        
        print("âœ… ç‰¹å®šé£é™©è¯†åˆ«æ­£ç¡®")
    
    def test_risk_scoring_accuracy(self):
        """æµ‹è¯•é£é™©è¯„åˆ†å‡†ç¡®æ€§"""
        print("\nğŸ§ª æµ‹è¯•é£é™©è¯„åˆ†å‡†ç¡®æ€§...")
        
        result = self.ai_client.analyze_task_risks(self.test_tasks)
        risky_tasks = result["risky_tasks"]
        
        # æ‰¾åˆ°ç‰¹å®šä»»åŠ¡çš„é£é™©è¯„åˆ†
        overdue_task = next((t for t in risky_tasks if t["task"]["id"] == 1), None)
        self.assertIsNotNone(overdue_task, "é€¾æœŸä»»åŠ¡åº”è¯¥è¢«è¯†åˆ«ä¸ºé£é™©ä»»åŠ¡")
        
        # éªŒè¯é€¾æœŸä»»åŠ¡æœ‰é«˜é£é™©åˆ†æ•°ï¼ˆä¸ä¸€å®šæ˜¯æœ€é«˜ï¼Œå› ä¸ºå…¶ä»–å› ç´ ä¹Ÿä¼šå½±å“ï¼‰
        self.assertGreaterEqual(overdue_task["risk_score"], 10.0, "é€¾æœŸä»»åŠ¡åº”è¯¥æœ‰å¾ˆé«˜çš„é£é™©åˆ†æ•°")
        
        print(f"ğŸ“Š æœ€é«˜é£é™©ä»»åŠ¡: {overdue_task['task']['title']} (åˆ†æ•°: {overdue_task['risk_score']})")
        
        # éªŒè¯é£é™©ç­‰çº§åˆ†ç±»
        critical_tasks = [t for t in risky_tasks if t["risk_level"] == "critical"]
        high_tasks = [t for t in risky_tasks if t["risk_level"] == "high"]
        
        print(f"ğŸš¨ ä¸¥é‡é£é™©ä»»åŠ¡: {len(critical_tasks)}")
        print(f"âš ï¸ é«˜é£é™©ä»»åŠ¡: {len(high_tasks)}")
        
        self.assertGreater(len(critical_tasks) + len(high_tasks), 0, "åº”è¯¥æœ‰é«˜é£é™©æˆ–ä¸¥é‡é£é™©ä»»åŠ¡")
    
    def test_enhanced_recommendations(self):
        """æµ‹è¯•å¢å¼ºçš„å»ºè®®åŠŸèƒ½"""
        print("\nğŸ§ª æµ‹è¯•å¢å¼ºçš„å»ºè®®åŠŸèƒ½...")
        
        result = self.ai_client.analyze_task_risks(self.test_tasks)
        risky_tasks = result["risky_tasks"]
        
        # éªŒè¯å»ºè®®åŒ…å«emojiå’Œå…·ä½“è¡ŒåŠ¨
        for risky_task in risky_tasks[:3]:  # æ£€æŸ¥å‰3ä¸ªé«˜é£é™©ä»»åŠ¡
            recommendations = risky_task["recommendations"]
            self.assertGreater(len(recommendations), 0, "æ¯ä¸ªé£é™©ä»»åŠ¡éƒ½åº”è¯¥æœ‰å»ºè®®")
            
            # éªŒè¯å»ºè®®åŒ…å«emojiï¼ˆå¢å¼ºç”¨æˆ·ä½“éªŒï¼‰
            has_emoji = any(any(ord(char) > 127 for char in rec) for rec in recommendations)
            self.assertTrue(has_emoji, "å»ºè®®åº”è¯¥åŒ…å«emojiä»¥æå‡ç”¨æˆ·ä½“éªŒ")
            
            print(f"ğŸ’¡ ä»»åŠ¡ '{risky_task['task']['title']}' çš„å»ºè®®:")
            for rec in recommendations:
                print(f"   - {rec}")
    
    def test_priority_adjustment(self):
        """æµ‹è¯•ä¼˜å…ˆçº§è°ƒæ•´å»ºè®®"""
        print("\nğŸ§ª æµ‹è¯•ä¼˜å…ˆçº§è°ƒæ•´å»ºè®®...")
        
        result = self.ai_client.analyze_task_risks(self.test_tasks)
        risky_tasks = result["risky_tasks"]
        
        # æŸ¥æ‰¾æœ‰ä¼˜å…ˆçº§è°ƒæ•´å»ºè®®çš„ä»»åŠ¡
        tasks_with_adjustments = [t for t in risky_tasks if t["priority_adjustment"]["adjustment"] > 0]
        
        print(f"ğŸ” æ£€æŸ¥ä¼˜å…ˆçº§è°ƒæ•´å»ºè®®:")
        for task in risky_tasks[:3]:
            adjustment = task["priority_adjustment"]
            print(f"   ä»»åŠ¡: {task['task']['title']}")
            print(f"   å½“å‰ä¼˜å…ˆçº§: P{task['task']['urgency']}")
            print(f"   è°ƒæ•´å€¼: {adjustment['adjustment']}")
            print(f"   å»ºè®®ä¼˜å…ˆçº§: P{adjustment['suggested_urgency']}")
            print(f"   é£é™©ç±»åˆ«: {task['risk_categories']}")
            print()
        
        # å¦‚æœæ²¡æœ‰è‡ªåŠ¨è°ƒæ•´å»ºè®®ï¼Œè‡³å°‘éªŒè¯é€»è¾‘æ˜¯æ­£ç¡®çš„
        if len(tasks_with_adjustments) == 0:
            print("â„¹ï¸ æ²¡æœ‰è‡ªåŠ¨ä¼˜å…ˆçº§è°ƒæ•´å»ºè®®ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºä»»åŠ¡å·²ç»æ˜¯åˆé€‚çš„ä¼˜å…ˆçº§")
            # æ£€æŸ¥æ˜¯å¦æœ‰P0ä»»åŠ¡å·²ç»é€¾æœŸï¼ˆä¸éœ€è¦è°ƒæ•´ï¼‰
            overdue_p0_tasks = [t for t in risky_tasks if t["task"]["urgency"] == 0 and "overdue" in t["risk_categories"]]
            if overdue_p0_tasks:
                print("âœ… å‘ç°P0é€¾æœŸä»»åŠ¡ï¼Œæ— éœ€è°ƒæ•´ä¼˜å…ˆçº§")
                return  # æµ‹è¯•é€šè¿‡
        
        self.assertGreaterEqual(len(tasks_with_adjustments), 0, "åº”è¯¥æœ‰ä»»åŠ¡éœ€è¦ä¼˜å…ˆçº§è°ƒæ•´æˆ–è€…æœ‰åˆç†çš„è§£é‡Š")
        
        for task in tasks_with_adjustments:
            adjustment = task["priority_adjustment"]
            print(f"ğŸ¯ ä»»åŠ¡ '{task['task']['title']}' å»ºè®®ä¼˜å…ˆçº§è°ƒæ•´:")
            print(f"   å½“å‰ä¼˜å…ˆçº§: P{task['task']['urgency']}")
            print(f"   å»ºè®®ä¼˜å…ˆçº§: P{adjustment['suggested_urgency']}")
            print(f"   è°ƒæ•´åŸå› : {', '.join(adjustment['reasons'])}")
    
    def test_impact_estimation(self):
        """æµ‹è¯•å½±å“è¯„ä¼°åŠŸèƒ½"""
        print("\nğŸ§ª æµ‹è¯•å½±å“è¯„ä¼°åŠŸèƒ½...")
        
        result = self.ai_client.analyze_task_risks(self.test_tasks)
        risky_tasks = result["risky_tasks"]
        
        for risky_task in risky_tasks[:3]:
            impact = risky_task["estimated_impact"]
            
            # éªŒè¯å½±å“è¯„ä¼°ç»“æ„
            self.assertIn("impact_score", impact)
            self.assertIn("impact_areas", impact)
            self.assertIn("severity", impact)
            
            print(f"ğŸ’¥ ä»»åŠ¡ '{risky_task['task']['title']}' å½±å“è¯„ä¼°:")
            print(f"   å½±å“åˆ†æ•°: {impact['impact_score']}")
            print(f"   ä¸¥é‡ç¨‹åº¦: {impact['severity']}")
            print(f"   å½±å“é¢†åŸŸ: {', '.join(impact['impact_areas'])}")
    
    def test_action_items_generation(self):
        """æµ‹è¯•è¡ŒåŠ¨é¡¹ç”Ÿæˆ"""
        print("\nğŸ§ª æµ‹è¯•è¡ŒåŠ¨é¡¹ç”Ÿæˆ...")
        
        result = self.ai_client.analyze_task_risks(self.test_tasks)
        action_items = result["action_items"]
        
        self.assertGreater(len(action_items), 0, "åº”è¯¥ç”Ÿæˆè¡ŒåŠ¨é¡¹")
        self.assertLessEqual(len(action_items), 5, "è¡ŒåŠ¨é¡¹ä¸åº”è¶…è¿‡5ä¸ª")
        
        print("ğŸ“‹ ç”Ÿæˆçš„è¡ŒåŠ¨é¡¹:")
        for i, item in enumerate(action_items, 1):
            print(f"{i}. ä»»åŠ¡: {item['task_title']}")
            print(f"   è¡ŒåŠ¨: {item['action']}")
            print(f"   ç´§æ€¥ç¨‹åº¦: {item['urgency']}")
            print(f"   æˆªæ­¢æ—¶é—´: {item['deadline']}")
            print()
    
    def test_project_insights(self):
        """æµ‹è¯•é¡¹ç›®æ´å¯ŸåŠŸèƒ½"""
        print("\nğŸ§ª æµ‹è¯•é¡¹ç›®æ´å¯ŸåŠŸèƒ½...")
        
        result = self.ai_client.analyze_task_risks(self.test_tasks)
        insights = result["project_insights"]
        
        # éªŒè¯æ´å¯Ÿç»“æ„
        required_fields = ["overall_health", "key_concerns", "strengths", "recommendations"]
        for field in required_fields:
            self.assertIn(field, insights)
        
        print(f"ğŸ¥ é¡¹ç›®æ•´ä½“å¥åº·çŠ¶å†µ: {insights['overall_health']}")
        
        if insights["key_concerns"]:
            print("âš ï¸ ä¸»è¦å…³æ³¨ç‚¹:")
            for concern in insights["key_concerns"]:
                print(f"   - {concern}")
        
        if insights["strengths"]:
            print("ğŸ’ª é¡¹ç›®ä¼˜åŠ¿:")
            for strength in insights["strengths"]:
                print(f"   - {strength}")
        
        if insights["recommendations"]:
            print("ğŸ¯ é¡¹ç›®å»ºè®®:")
            for rec in insights["recommendations"]:
                print(f"   - {rec}")
    
    def test_risk_distribution(self):
        """æµ‹è¯•é£é™©åˆ†å¸ƒåˆ†æ"""
        print("\nğŸ§ª æµ‹è¯•é£é™©åˆ†å¸ƒåˆ†æ...")
        
        result = self.ai_client.analyze_task_risks(self.test_tasks)
        distribution = result["risk_distribution"]
        
        # éªŒè¯åˆ†å¸ƒç»“æ„
        self.assertIn("by_category", distribution)
        self.assertIn("by_module", distribution)
        self.assertIn("total_risky_tasks", distribution)
        
        print("ğŸ“Š æŒ‰é£é™©ç±»åˆ«åˆ†å¸ƒ:")
        for category, count in distribution["by_category"].items():
            print(f"   {category}: {count}")
        
        print("ğŸ“Š æŒ‰æ¨¡å—åˆ†å¸ƒ:")
        for module, count in distribution["by_module"].items():
            print(f"   æ¨¡å— {module}: {count}")
        
        print(f"ğŸ“Š æ€»é£é™©ä»»åŠ¡æ•°: {distribution['total_risky_tasks']}")
    
    def test_enhanced_suggestions(self):
        """æµ‹è¯•å¢å¼ºçš„æ•´ä½“å»ºè®®"""
        print("\nğŸ§ª æµ‹è¯•å¢å¼ºçš„æ•´ä½“å»ºè®®...")
        
        result = self.ai_client.analyze_task_risks(self.test_tasks)
        suggestions = result["suggestions"]
        
        self.assertGreater(len(suggestions), 0, "åº”è¯¥æœ‰æ•´ä½“å»ºè®®")
        self.assertLessEqual(len(suggestions), 5, "å»ºè®®ä¸åº”è¶…è¿‡5æ¡")
        
        print("ğŸ’¡ é¡¹ç›®æ•´ä½“å»ºè®®:")
        for i, suggestion in enumerate(suggestions, 1):
            print(f"{i}. {suggestion}")
    
    def test_performance_with_large_dataset(self):
        """æµ‹è¯•å¤§æ•°æ®é›†æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•å¤§æ•°æ®é›†æ€§èƒ½...")
        
        # åˆ›å»ºå¤§é‡æµ‹è¯•æ•°æ®
        large_dataset = []
        for i in range(100):
            task = {
                "id": i + 100,
                "title": f"ä»»åŠ¡ {i+100}",
                "description": f"æè¿° {i+100}" + (" å»¶æœŸ" if i % 10 == 0 else ""),
                "urgency": i % 4,
                "module_id": i % 5,
                "created_at": (datetime.now() - timedelta(days=i % 60)).isoformat(),
                "dependencies": [j for j in range(max(0, i-2), i)]
            }
            large_dataset.append(task)
        
        start_time = datetime.now()
        result = self.ai_client.analyze_task_risks(large_dataset)
        end_time = datetime.now()
        
        processing_time = (end_time - start_time).total_seconds()
        
        print(f"â±ï¸ å¤„ç†100ä¸ªä»»åŠ¡è€—æ—¶: {processing_time:.2f}ç§’")
        print(f"ğŸ“Š è¯†åˆ«å‡º {len(result['risky_tasks'])} ä¸ªé£é™©ä»»åŠ¡")
        
        # æ€§èƒ½åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆ<5ç§’ï¼‰
        self.assertLess(processing_time, 5.0, "å¤§æ•°æ®é›†å¤„ç†æ—¶é—´åº”è¯¥åœ¨5ç§’å†…")
    
    def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è¿è¡Œå¢å¼ºç‰ˆé£é™©é›·è¾¾å…¨é¢æµ‹è¯•...")
        print("=" * 60)
        
        # åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ
        self.setUp()
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_methods = [
            self.test_enhanced_risk_analysis_basic,
            self.test_enhanced_risk_categories,
            self.test_risk_scoring_accuracy,
            self.test_enhanced_recommendations,
            self.test_priority_adjustment,
            self.test_impact_estimation,
            self.test_action_items_generation,
            self.test_project_insights,
            self.test_risk_distribution,
            self.test_enhanced_suggestions,
            self.test_performance_with_large_dataset
        ]
        
        passed_tests = 0
        total_tests = len(test_methods)
        
        for test_method in test_methods:
            try:
                test_method()
                passed_tests += 1
                print("âœ… æµ‹è¯•é€šè¿‡")
            except Exception as e:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            print("-" * 40)
        
        print(f"\nğŸ¯ æµ‹è¯•ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡")
        print(f"ğŸ“Š é€šè¿‡ç‡: {passed_tests/total_tests*100:.1f}%")
        
        if passed_tests == total_tests:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¢å¼ºç‰ˆé£é™©é›·è¾¾åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼")
        else:
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        
        return passed_tests == total_tests

if __name__ == "__main__":
    # è¿è¡Œå…¨é¢æµ‹è¯•
    tester = TestEnhancedRiskRadar()
    tester.run_comprehensive_test() 