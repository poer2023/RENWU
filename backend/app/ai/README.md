# TaskWall v3.0 AI Services

TaskWall v3.0çš„æ™ºèƒ½ä»»åŠ¡ç®¡ç†AIæœåŠ¡å¥—ä»¶ï¼Œæä¾›å…¨é¢çš„AIé©±åŠ¨ä»»åŠ¡ç®¡ç†åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€å¯¼å…¥
```python
from app.ai import (
    AIServiceAggregator,    # ç»Ÿä¸€AIæœåŠ¡å…¥å£
    NLPService,            # è‡ªç„¶è¯­è¨€å¤„ç†
    ClassificationService,  # ä»»åŠ¡åˆ†ç±»
    SimilarityService,     # ç›¸ä¼¼åº¦æ£€æµ‹
    PriorityService,       # ä¼˜å…ˆçº§è¯„ä¼°
    DependencyService,     # ä¾èµ–åˆ†æ
    WorkloadService,       # å·¥ä½œè´Ÿè½½ç®¡ç†
    VectorDBManager        # å‘é‡æ•°æ®åº“
)
```

### åˆ›å»ºAIèšåˆå™¨
```python
from sqlalchemy.orm import Session
from app.ai import AIServiceAggregator

# ä½¿ç”¨æ•°æ®åº“ä¼šè¯åˆ›å»ºèšåˆå™¨
aggregator = AIServiceAggregator(db_session)
```

## ğŸ§  æ ¸å¿ƒåŠŸèƒ½

### 1. è‡ªç„¶è¯­è¨€ä»»åŠ¡å¤„ç†
å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºç»“æ„åŒ–ä»»åŠ¡ï¼š

```python
# å¤„ç†å•ä¸ªè‡ªç„¶è¯­è¨€è¾“å…¥
suggestion = aggregator.process_natural_language_task(
    text="ç´§æ€¥ä¿®å¤ç™»å½•é¡µé¢bugï¼Œä»Šå¤©å¿…é¡»å®Œæˆ",
    context={"user_id": "user123"},
    full_analysis=True
)

print(f"å»ºè®®ä»»åŠ¡: {suggestion.suggested_task['title']}")
print(f"ç½®ä¿¡åº¦: {suggestion.confidence}")
print(f"ç›¸ä¼¼ä»»åŠ¡: {len(suggestion.similar_tasks)}ä¸ª")
```

### 2. ä»»åŠ¡åˆ†æ
å¯¹ç°æœ‰ä»»åŠ¡è¿›è¡Œå…¨é¢AIåˆ†æï¼š

```python
# åˆ†æç°æœ‰ä»»åŠ¡
task_data = {
    "id": 1,
    "title": "å¼€å‘ç”¨æˆ·ç™»å½•API",
    "description": "å®ç°ç”¨æˆ·èº«ä»½éªŒè¯æ¥å£",
    "category": "å¼€å‘",
    "priority": 2,
    "deadline": "2024-01-15T18:00:00Z"
}

analysis = aggregator.analyze_existing_task(
    task_data=task_data,
    context={"all_tasks": [...], "user_tasks": [...]}
)

print(f"åˆ†ç±»ç»“æœ: {analysis.classification_result.data}")
print(f"ä¼˜å…ˆçº§: {analysis.priority_result.data}")
print(f"ç›¸ä¼¼ä»»åŠ¡: {len(analysis.similarity_result.data)}")
```

### 3. ä»»åŠ¡åˆ—è¡¨ä¼˜åŒ–
ä¼˜åŒ–æ•´ä¸ªä»»åŠ¡åˆ—è¡¨ï¼š

```python
# ä¼˜åŒ–ä»»åŠ¡åˆ—è¡¨
tasks = [
    {"id": 1, "title": "ä»»åŠ¡A", "category": "å¼€å‘"},
    {"id": 2, "title": "ä»»åŠ¡B", "category": "æµ‹è¯•"},
    # ... æ›´å¤šä»»åŠ¡
]

optimization = aggregator.optimize_task_list(
    tasks=tasks,
    context={"time_frame": "this_week"}
)

print(f"ä¼˜åŒ–å»ºè®®: {optimization['recommendations']}")
print(f"æœ€ä¼˜æ‰§è¡Œé¡ºåº: {optimization['optimized_order']}")
```

### 4. æ‰¹é‡å¤„ç†
æ‰¹é‡å¤„ç†å¤šä¸ªè‡ªç„¶è¯­è¨€è¾“å…¥ï¼š

```python
# æ‰¹é‡å¤„ç†
task_inputs = [
    "ä¿®å¤æ”¯ä»˜bug",
    "è®¾è®¡æ–°ç•Œé¢",
    "æµ‹è¯•APIæ¥å£"
]

results = aggregator.batch_process_tasks(task_inputs)
for result in results:
    print(f"ä»»åŠ¡: {result.suggested_task['title']}")
```

## ğŸ”§ å•ç‹¬ä½¿ç”¨AIæœåŠ¡

### NLPæœåŠ¡
```python
nlp_service = NLPService(db_session)
result = nlp_service.process({
    "text": "æ˜å¤©å¼€ä¼šè®¨è®ºé¡¹ç›®è¿›åº¦",
    "context": {}
})
```

### åˆ†ç±»æœåŠ¡
```python
classification_service = ClassificationService(db_session)
result = classification_service.process({
    "task_content": "å¼€å‘ç™»å½•API",
    "user_context": {}
})
```

### ä¼˜å…ˆçº§æœåŠ¡
```python
priority_service = PriorityService(db_session)
result = priority_service.process({
    "task_data": {
        "title": "ç´§æ€¥bugä¿®å¤",
        "deadline": "2024-01-15T18:00:00Z"
    },
    "context": {}
})
```

### ç›¸ä¼¼åº¦æœåŠ¡
```python
similarity_service = SimilarityService(db_session)
result = similarity_service.process({
    "task_content": "ä¿®å¤ç™»å½•é—®é¢˜",
    "threshold": 0.7,
    "max_results": 5
})
```

### ä¾èµ–æœåŠ¡
```python
dependency_service = DependencyService(db_session)
result = dependency_service.process({
    "operation": "detect",
    "tasks": [...],
    "context": {}
})
```

### å·¥ä½œè´Ÿè½½æœåŠ¡
```python
workload_service = WorkloadService(db_session)
result = workload_service.process({
    "operation": "analyze",
    "tasks": [...],
    "time_frame": "this_week",
    "context": {}
})
```

## ğŸ“Š AIæ´å¯Ÿ

è·å–AIé©±åŠ¨çš„ç”¨æˆ·æ´å¯Ÿï¼š

```python
insights = aggregator.get_ai_insights(
    user_id="user123",
    time_frame="this_week"
)

print(f"å·¥ä½œè´Ÿè½½: {insights['insights']['workload']}")
print(f"ä¼˜å…ˆçº§åˆ†å¸ƒ: {insights['insights']['priorities']}")
print(f"å»ºè®®: {insights['insights']['recommendations']}")
```

## ğŸ” æœåŠ¡çŠ¶æ€ç›‘æ§

æ£€æŸ¥AIæœåŠ¡å¥åº·çŠ¶æ€ï¼š

```python
status = aggregator.get_service_status()
print(f"æ•´ä½“å¥åº·çŠ¶æ€: {status['overall_health']}")
print(f"æœåŠ¡çŠ¶æ€: {status['services']}")
print(f"å‘é‡æ•°æ®åº“: {status['vector_database']}")
```

## âš™ï¸ é…ç½®

### ç¯å¢ƒä¾èµ–
- **å¿…éœ€**: SQLModel, FastAPI, æ•°æ®åº“è¿æ¥
- **å¯é€‰**: Redis (ç¼“å­˜), ChromaDB (å‘é‡æœç´¢), sentence-transformers (è¯­ä¹‰ç›¸ä¼¼åº¦)

### é…ç½®é€‰é¡¹
```python
# ç¼“å­˜é…ç½®
cache = AICache(redis_client=your_redis_client)

# å‘é‡æ•°æ®åº“é…ç½®
vector_db = VectorDBManager(
    db_session,
    persist_directory="./data/chroma"
)

# å¸¦ç¼“å­˜çš„æœåŠ¡
service = NLPService(db_session, cache=cache)
```

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–

### å¹¶è¡Œå¤„ç†
AIèšåˆå™¨è‡ªåŠ¨å¹¶è¡Œæ‰§è¡Œå¤šä¸ªAIæœåŠ¡ï¼Œæé«˜å¤„ç†é€Ÿåº¦ã€‚

### æ™ºèƒ½ç¼“å­˜
- Redisç¼“å­˜çƒ­é—¨æŸ¥è¯¢ç»“æœ
- å‘é‡æ•°æ®åº“ç¼“å­˜è¯­ä¹‰æœç´¢
- åˆ†å±‚TTLç­–ç•¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨

### ä¼˜é›…é™çº§
- Redisä¸å¯ç”¨æ—¶è‡ªåŠ¨ç¦ç”¨ç¼“å­˜
- ChromaDBä¸å¯ç”¨æ—¶ä½¿ç”¨è§„åˆ™åŒ¹é…
- æœåŠ¡å¼‚å¸¸æ—¶æä¾›å¤‡ç”¨ç­–ç•¥

## ğŸ”§ é”™è¯¯å¤„ç†

```python
from app.ai.base import AIError

try:
    result = aggregator.process_natural_language_task("...")
except AIError as e:
    print(f"AIæ“ä½œå¤±è´¥: {e.message}")
    print(f"æ“ä½œç±»å‹: {e.operation}")
    if e.original_error:
        print(f"åŸå§‹é”™è¯¯: {e.original_error}")
```

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

AIæœåŠ¡è‡ªåŠ¨è®°å½•ï¼š
- æ“ä½œæ—¥å¿—ï¼ˆAILogè¡¨ï¼‰
- ç”¨æˆ·åé¦ˆï¼ˆAIFeedbackè¡¨ï¼‰
- æ€§èƒ½æŒ‡æ ‡
- é”™è¯¯è¿½è¸ª

æŸ¥çœ‹AIæ—¥å¿—ï¼š
```python
from app.models import AILog
logs = db_session.query(AILog).filter(
    AILog.operation == "parse"
).order_by(AILog.created_at.desc()).limit(10).all()
```

## ğŸš€ é›†æˆåˆ°API

FastAPIé›†æˆç¤ºä¾‹ï¼š
```python
from fastapi import APIRouter, Depends
from app.ai import AIServiceAggregator

router = APIRouter()

@router.post("/ai/parse-task")
async def parse_task(
    text: str,
    aggregator: AIServiceAggregator = Depends(get_ai_aggregator)
):
    suggestion = aggregator.process_natural_language_task(text)
    return suggestion.suggested_task

@router.post("/ai/analyze-task")
async def analyze_task(
    task_data: dict,
    aggregator: AIServiceAggregator = Depends(get_ai_aggregator)
):
    analysis = aggregator.analyze_existing_task(task_data)
    return {
        "classification": analysis.classification_result.data,
        "priority": analysis.priority_result.data,
        "recommendations": analysis.recommendations
    }
```

## ğŸ§ª æµ‹è¯•

è¿è¡Œæµ‹è¯•å¥—ä»¶ï¼š
```bash
# åŸºç¡€å¯¼å…¥æµ‹è¯•
python test_ai_services.py

# åŠŸèƒ½æ¼”ç¤º
python demo_ai_features.py
```

## ğŸ“ æœ€ä½³å®è·µ

1. **ä½¿ç”¨èšåˆå™¨**: æ¨èä½¿ç”¨`AIServiceAggregator`è€Œä¸æ˜¯ç›´æ¥è°ƒç”¨å•ç‹¬æœåŠ¡
2. **æä¾›ä¸Šä¸‹æ–‡**: å°½å¯èƒ½æä¾›ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯æé«˜AIå‡†ç¡®æ€§
3. **ç¼“å­˜ç­–ç•¥**: åœ¨ç”Ÿäº§ç¯å¢ƒä¸­é…ç½®Redisç¼“å­˜
4. **é”™è¯¯å¤„ç†**: å¦¥å–„å¤„ç†AIæœåŠ¡å¯èƒ½çš„å¼‚å¸¸æƒ…å†µ
5. **ç›‘æ§æ—¥å¿—**: å®šæœŸæ£€æŸ¥AIæ“ä½œæ—¥å¿—å’Œæ€§èƒ½æŒ‡æ ‡
6. **ç”¨æˆ·åé¦ˆ**: æ”¶é›†ç”¨æˆ·åé¦ˆæŒç»­æ”¹è¿›AIæ¨¡å‹

## ğŸ”® æœªæ¥æ‰©å±•

TaskWall v3.0 AIæœåŠ¡è®¾è®¡ä¸ºé«˜åº¦å¯æ‰©å±•ï¼š
- æ–°å¢AIæœåŠ¡åªéœ€ç»§æ‰¿`AIServiceBase`
- æ”¯æŒè‡ªå®šä¹‰AIæ¨¡å‹é›†æˆ
- å¯æ‰©å±•çš„å‘é‡æ•°æ®åº“åç«¯
- æ’ä»¶åŒ–çš„åˆ†æç­–ç•¥

---

**æ³¨æ„**: è¿™æ˜¯TaskWall v3.0 Sprint 1çš„AIåŸºç¡€è®¾æ–½å®ç°ã€‚éšç€é¡¹ç›®å‘å±•ï¼Œæ›´å¤šé«˜çº§åŠŸèƒ½å°†åœ¨åç»­Sprintä¸­æ¨å‡ºã€‚